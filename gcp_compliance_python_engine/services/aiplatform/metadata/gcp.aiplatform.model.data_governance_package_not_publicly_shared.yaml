rule_id: gcp.aiplatform.model.data_governance_package_not_publicly_shared
service: aiplatform
resource: model
requirement: Data Governance Package Not Publicly Shared
scope: aiplatform.model.public_access
domain: identity_and_access_management
subcategory: authentication
severity: critical
title: Ensure AI Platform Model Data Governance Package is Not Publicly Shared
rationale: Publicly sharing AI model data governance packages can lead to unauthorized
  access, data breaches, and exploitation of sensitive information. This exposure
  can result in financial loss, reputational damage, and non-compliance with privacy
  regulations such as GDPR and CCPA, undermining trust and operational integrity.
description: This rule checks the access permissions of AI Platform model data governance
  packages to ensure they are not publicly accessible. It verifies that IAM policies
  restrict access only to authorized users and groups. If public sharing is detected,
  it is critical to immediately revise IAM settings to limit access. Remediation involves
  removing 'allUsers' or 'allAuthenticatedUsers' from the IAM policy bindings of the
  model resource.
references:
- https://cloud.google.com/ai-platform-unified/docs/permissions-ai-platform
- https://cloud.google.com/security-command-center/docs/how-to-remediate-security-findings
- https://cloud.google.com/iam/docs/understanding-service-accounts
- https://www.cisecurity.org/benchmark/google_cloud_computing_platform/
- https://www.iso.org/iso-27001-information-security.html
- https://www.nist.gov/cyberframework
