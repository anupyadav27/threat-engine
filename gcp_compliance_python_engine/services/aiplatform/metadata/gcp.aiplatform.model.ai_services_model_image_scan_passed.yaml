rule_id: gcp.aiplatform.model.ai_services_model_image_scan_passed
service: aiplatform
resource: model
requirement: Ai Services Model Image Scan Passed
scope: aiplatform.model.security
domain: container_and_kubernetes_security
subcategory: security_monitoring
severity: low
title: Ensure AI Model Images Pass Security Scans
rationale: Unscanned AI model images can harbor vulnerabilities that may be exploited
  by attackers, leading to unauthorized access or data breaches. Regular scanning
  of model images mitigates these risks by identifying and addressing vulnerabilities
  before deployment, ensuring compliance with security standards and protecting organizational
  assets.
description: This rule verifies that AI model images in the Google Cloud AI Platform
  have passed security scans for vulnerabilities. It involves configuring automatic
  image scanning using Google Cloud's Container Analysis API and monitoring scan results.
  If vulnerabilities are detected, remediate them by updating the image or applying
  necessary patches before deploying the model. Regularly review and maintain scanning
  configurations to ensure new images are also scanned.
references:
- https://cloud.google.com/container-analysis/docs/overview
- https://cloud.google.com/security-command-center/docs/posture-management-overview
- https://www.cisecurity.org/benchmark/google_cloud_computing_platform
- https://cloud.google.com/security/compliance
- https://cloud.google.com/ai-platform/training/docs/using-containers
