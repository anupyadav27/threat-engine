rule_id: gcp.aiplatform.model.machine_learning_package_artifact_signed_and_verified
service: aiplatform
resource: model
requirement: Machine Learning Package Artifact Signed And Verified
scope: aiplatform.model.security
domain: compliance_and_governance
subcategory: security_monitoring
severity: low
title: Ensure ML Artifacts are Signed and Verified
rationale: Ensuring that machine learning package artifacts are signed and verified
  mitigates the risk of deploying malicious code, which can lead to data breaches,
  model corruption, and business disruption. This practice is crucial for maintaining
  integrity and trust in AI models, aligning with compliance standards such as SOC2
  and ISO 27001.
description: This rule checks whether all machine learning package artifacts in the
  AI Platform are signed and verified before deployment. Verification ensures that
  only authorized and untampered artifacts are deployed, preventing potential security
  breaches. To remediate, ensure the signing process is integrated into the CI/CD
  pipeline and that verification occurs before deployment. Use GCP's Binary Authorization
  to enforce this policy.
references:
- https://cloud.google.com/ai-platform-unified/docs/general/security-overview
- https://cloud.google.com/binary-authorization/docs/overview
- https://www.cisecurity.org/benchmark/google_cloud_computing_platform
- https://www.iso.org/iso-27001-information-security.html
- https://cloud.google.com/security/compliance/soc-2
- https://cloud.google.com/security/compliance
