rule_id: gcp.aiplatform.model.ai_services_supply_chain_model_artifact_signed_and_verified
service: aiplatform
resource: model
requirement: Ai Services Supply Chain Model Artifact Signed And Verified
scope: aiplatform.model.security
domain: compliance_and_governance
subcategory: security_monitoring
severity: low
title: Verify AI Model Artifacts with Signed and Trusted Certificates
rationale: Ensuring that AI model artifacts are signed and verified protects against
  the introduction of malicious or tampered code, which can lead to unauthorized data
  access or manipulation. This practice is essential for maintaining the integrity
  of AI systems, meeting compliance requirements, and safeguarding business operations
  from potential threats.
description: This rule checks that AI model artifacts in Google Cloud's AI Platform
  are signed with a trusted certificate and verified before deployment. To verify,
  ensure that all model artifacts have been signed using a certificate from a trusted
  Certificate Authority (CA) and that the verification process is in place to check
  the signatures before model execution. Remediation involves configuring the AI Platform
  to enforce signature verification before loading models, using tools like Binary
  Authorization for verification workflows.
references:
- https://cloud.google.com/ai-platform/deep-learning-vm/docs/security-best-practices
- https://cloud.google.com/binary-authorization/docs/overview
- https://www.cisecurity.org/benchmark/google_cloud_computing_platform
- https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-190.pdf
- https://cloud.google.com/security/compliance
