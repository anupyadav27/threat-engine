rule_id: gcp.aiplatform.model.ai_services_model_version_image_scan_passed
service: aiplatform
resource: model
requirement: Ai Services Model Version Image Scan Passed
scope: aiplatform.model.security
domain: container_and_kubernetes_security
subcategory: security_monitoring
severity: low
title: Ensure AI Model Image Scans Pass Security Checks
rationale: Unscanned or vulnerable images in AI models can introduce security risks,
  such as unauthorized code execution or data breaches, potentially leading to financial
  loss or reputational damage. Ensuring images pass security scans helps mitigate
  these risks by identifying vulnerabilities before deployment, aligning with compliance
  standards like PCI-DSS and ISO 27001, and supporting secure AI service operations.
description: This rule checks if AI Platform model versions have their container images
  scanned for vulnerabilities, ensuring any detected issues are addressed before deployment.
  To verify, ensure that the image scanning feature is enabled and configured to block
  deployments of images with high-severity vulnerabilities. Remediation involves configuring
  automatic scans and reviewing scan results regularly, addressing any critical or
  high vulnerabilities immediately.
references:
- https://cloud.google.com/ai-platform/docs/security-overview
- https://cloud.google.com/container-analysis/docs/container-scanning
- https://www.cisecurity.org/benchmark/google_cloud_computing_platform
- https://www.pcisecuritystandards.org/pci_security/
- https://www.iso.org/isoiec-27001-information-security.html
- https://csrc.nist.gov/publications/detail/sp/800-207/final
