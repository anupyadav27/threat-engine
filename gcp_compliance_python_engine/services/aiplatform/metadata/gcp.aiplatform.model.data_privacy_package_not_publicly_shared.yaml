rule_id: gcp.aiplatform.model.data_privacy_package_not_publicly_shared
service: aiplatform
resource: model
requirement: Data Privacy Package Not Publicly Shared
scope: aiplatform.model.public_access
domain: data_protection_and_privacy
subcategory: encryption_at_rest
severity: critical
title: Ensure AI Platform Model Data Privacy Packages Not Publicly Shared
rationale: Publicly sharing AI model data privacy packages can lead to unauthorized
  access to sensitive data, increasing the risk of data breaches and non-compliance
  with data protection regulations such as GDPR and CCPA. This could expose the organization
  to significant legal liabilities and reputational damage.
description: This rule checks whether the data privacy packages associated with AI
  Platform models are publicly shared. Ensuring these packages are not publicly accessible
  is crucial for safeguarding sensitive data. Administrators should verify that IAM
  policies are correctly configured to restrict public access and apply encryption
  at rest to protect data integrity. Remediation involves reviewing and updating access
  controls and encryption settings in the GCP Console under the AI Platform's model
  permissions.
references:
- https://cloud.google.com/ai-platform/docs/security-overview
- https://cloud.google.com/iam/docs/granting-changing-revoking-access
- https://www.cisecurity.org/benchmark/google_cloud_computing_platform
- https://www.iso.org/iso-27001-information-security.html
- https://www.nist.gov/cyberframework
- https://cloud.google.com/security/encryption-at-rest/default-encryption
