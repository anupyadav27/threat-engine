# ============================================================================
# CURSOR AI: GCP SERVICE VALIDATION INSTRUCTIONS
# ============================================================================
# 
# üéØ YOUR MISSION: Validate and fix this GCP service YAML file
#
# WORKFLOW:
# 1. Read this entire YAML file structure
# 2. Run: `export GCP_ENGINE_FILTER_SERVICES="<SERVICE>" && python engine/gcp_engine.py > output/test_<service>.json 2>&1`
# 3. Analyze output - check for inventories, main_checks, errors
# 4. Fix issues in discovery and checks sections below
# 5. Re-run engine and verify output
# 6. Iterate until all checks work (PASS/FAIL based on resources)
# 7. Update validation status at bottom of file
#
# COMMON ISSUES & FIXES:
#
# ‚ùå Empty inventories ‚Üí Fix discovery action (must be: list_<resource>, aggregatedList_<resource>)
# ‚ùå Zero checks executed ‚Üí Fix for_each to match discovery_id
# ‚ùå All checks fail ‚Üí Fix field paths to match GCP API response
# ‚ùå Skipped checks ‚Üí Verify discovery_id exists and completed
# ‚ùå Python errors ‚Üí Check YAML syntax, action names
#
# TESTING:
# - Run engine: `export GCP_ENGINE_FILTER_SERVICES="<service>" && python engine/gcp_engine.py > output/test.json 2>&1`
# - Check output: `cat output/test.json | python3 -m json.tool`
# - Verify: inventories array has resources, main_checks array has results
#
# SUCCESS CRITERIA:
# ‚úÖ Engine runs without Python exceptions
# ‚úÖ Inventories populated (if resources exist in GCP)
# ‚úÖ All checks execute (PASS/FAIL based on actual resource state)
# ‚úÖ No skipped checks (unless expected)
# ‚úÖ Clean JSON output
#
# DOCUMENTATION:
# After fixing, update validation section at bottom:
# # VALIDATION STATUS:
# # - Issues Found: <what was wrong>
# # - Fixes Applied: <what you fixed>
# # - Tested: <date>
# # - Inventories: <count>
# # - Checks: <count executed>
# # - Status: ‚úÖ VALIDATED / ‚è≥ IN PROGRESS / ‚ùå NEEDS WORK
#
# ============================================================================

service_name:  # e.g., compute, gcs, pubsub

bigtable:
  version: '1.0'
  provider: gcp
  service: bigtable
  scope: regional
  discovery:
  - discovery_id: list_bigtable_instances
    calls:
    - action: list
      fields:
      - path: name
        var: instance_name
      - path: displayName
        var: instance_display_name
      - path: type
        var: instance_type
  - discovery_id: list_bigtable_tables
    calls:
    - action: list
      fields:
      - path: name
        var: table_name
      - path: clusterStates
        var: cluster_states
      - path: columnFamilies
        var: column_families
  - discovery_id: list_bigtable_clusters
    calls:
    - action: list
      fields:
      - path: name
        var: cluster_name
      - path: location
        var: cluster_location
      - path: encryptionConfig
        var: encryption_config
  checks:
  - check_id: gcp.bigtable.instance.backup_enabled
    title: Enable Backups for Bigtable Instances
    severity: medium
    for_each: list_bigtable_instances
    logic: AND
    calls:
    - action: get_instance_backups
      fields:
      - path: backups
        operator: exists
        expected: true
    - action: eval
      fields:
      - path: backups
        operator: contains
        expected: backup
  - check_id: gcp.bigtable.table.data_protection_storage_global_cross_region_replic_encrypted
    title: Ensure Cross-Region Replicated Bigtable Data is Encrypted
    severity: high
    for_each: list_bigtable_tables
    logic: AND
    calls:
    - action: eval
      fields:
      - path: clusterStates
        operator: exists
        expected: true
    - action: get_table_replication_config
      fields:
      - path: replicationStates
        operator: exists
        expected: true
    - action: eval
      fields:
      - path: replicationStates[].encryptionInfo.encryptionType
        operator: equals
        expected: CUSTOMER_MANAGED_ENCRYPTION
  - check_id: gcp.bigtable.table.data_protection_storage_global_encryption_at_rest_al_regions
    title: Ensure Bigtable Tables Use CMEK for Encryption At Rest in All Regions
    severity: high
    for_each: list_bigtable_clusters
    logic: AND
    calls:
    - action: eval
      fields:
      - path: encryptionConfig
        operator: exists
        expected: true
    - action: eval
      fields:
      - path: encryptionConfig.kmsKeyName
        operator: exists
        expected: true
    - action: get_cluster_encryption_details
      fields:
      - path: encryptionConfig.kmsKeyName
        operator: contains
        expected: projects/
  - check_id: gcp.bigtable.table.data_protection_storage_global_pitr_enabled_where_supported
    title: Ensure Bigtable Global PITR is Enabled Where Supported
    severity: medium
    for_each: list_bigtable_tables
    logic: AND
    calls:
    - action: get_table_backup_policy
      fields:
      - path: changeStreamConfig
        operator: exists
        expected: true
    - action: eval
      fields:
      - path: changeStreamConfig.retentionPeriod
        operator: exists
        expected: true
    - action: eval
      fields:
      - path: changeStreamConfig.retentionPeriod
        operator: contains
        expected: s
  api_name: bigtableadmin
  api_version: v2
  project_param_format: projects/{{project_id}}
