#!/usr/bin/env python3
"""
Enhanced Service Regeneration with Intelligent Check Mapping

This script creates services with actual SDK-based checks by:
1. Analyzing rule metadata to determine check patterns
2. Mapping common security patterns to SDK field checks
3. Generating meaningful discovery and check logic
"""

import os
import yaml
import re
from collections import defaultdict
from pathlib import Path

# Paths
BASE_DIR = Path(__file__).parent
RULE_IDS_FILE = BASE_DIR / "rule_ids.yaml"
SERVICES_DIR = BASE_DIR / "services"

# Service-specific SDK configurations
SERVICE_SDK_CONFIG = {
    'ecs': {
        'product': 'Ecs',
        'version': '2014-05-26',
        'resources': {
            'instance': {
                'list_action': 'DescribeInstances',
                'list_response_key': 'Instances.Instance',
                'describe_action': 'DescribeInstanceAttribute',
                'id_field': 'InstanceId'
            },
            'disk': {
                'list_action': 'DescribeDisks',
                'list_response_key': 'Disks.Disk',
                'id_field': 'DiskId'
            },
            'security_group': {
                'list_action': 'DescribeSecurityGroups',
                'list_response_key': 'SecurityGroups.SecurityGroup',
                'id_field': 'SecurityGroupId'
            },
            'image': {
                'list_action': 'DescribeImages',
                'list_response_key': 'Images.Image',
                'id_field': 'ImageId'
            },
            'snapshot': {
                'list_action': 'DescribeSnapshots',
                'list_response_key': 'Snapshots.Snapshot',
                'id_field': 'SnapshotId'
            }
        }
    },
    'oss': {
        'product': 'Oss',
        'version': '2019-05-17',
        'resources': {
            'bucket': {
                'list_action': 'ListBuckets',
                'list_response_key': 'Buckets.Bucket',
                'id_field': 'Name'
            }
        }
    },
    'rds': {
        'product': 'Rds',
        'version': '2014-08-15',
        'resources': {
            'instance': {
                'list_action': 'DescribeDBInstances',
                'list_response_key': 'Items.DBInstance',
                'id_field': 'DBInstanceId'
            }
        }
    },
    'ram': {
        'product': 'Ram',
        'version': '2015-05-01',
        'resources': {
            'user': {
                'list_action': 'ListUsers',
                'list_response_key': 'Users.User',
                'id_field': 'UserId'
            },
            'policy': {
                'list_action': 'ListPolicies',
                'list_response_key': 'Policies.Policy',
                'id_field': 'PolicyName'
            }
        }
    },
    'vpc': {
        'product': 'Vpc',
        'version': '2016-04-28',
        'resources': {
            'vpc': {
                'list_action': 'DescribeVpcs',
                'list_response_key': 'Vpcs.Vpc',
                'id_field': 'VpcId'
            }
        }
    }
}

# Default config for unknown services
DEFAULT_SDK_CONFIG = {
    'product': 'Unknown',
    'version': '2014-05-26',
    'resources': {}
}


def load_rules():
    """Load all rules from rule_ids.yaml"""
    print(f"Loading rules from {RULE_IDS_FILE}...")
    with open(RULE_IDS_FILE, 'r') as f:
        data = yaml.safe_load(f)
    rules = data.get('rules', [])
    print(f"Loaded {len(rules)} rules")
    return rules


def group_by_service(rules):
    """Group rules by service name"""
    print("\nGrouping rules by service...")
    services = defaultdict(list)
    for rule in rules:
        service = rule.get('service', 'unknown')
        services[service].append(rule)
    
    print(f"Found {len(services)} services:")
    for service, rule_list in sorted(services.items(), key=lambda x: -len(x[1])):
        print(f"  - {service}: {len(rule_list)} rules")
    
    return dict(services)


def create_metadata_file(service_dir, rule):
    """Create individual metadata YAML file for a rule"""
    import hashlib
    
    metadata_dir = service_dir / "metadata"
    metadata_dir.mkdir(parents=True, exist_ok=True)
    
    rule_id = rule.get('rule_id', 'unknown')
    
    # Handle long filenames
    filename = f"{rule_id}.yaml"
    if len(filename) > 200:
        hash_suffix = hashlib.md5(rule_id.encode()).hexdigest()[:8]
        short_id = rule_id[:150]
        filename = f"{short_id}_{hash_suffix}.yaml"
    
    filepath = metadata_dir / filename
    
    # Extract metadata fields
    metadata = {
        'rule_id': rule_id,
        'service': rule.get('service'),
        'resource': rule.get('resource'),
        'requirement': rule.get('requirement'),
        'scope': rule.get('scope'),
        'domain': rule.get('domain'),
        'subcategory': rule.get('subcategory'),
        'severity': rule.get('severity'),
        'title': rule.get('title'),
        'rationale': rule.get('rationale'),
        'description': rule.get('description'),
        'references': rule.get('references', [])
    }
    
    if 'compliance' in rule:
        metadata['compliance'] = rule['compliance']
    
    metadata = {k: v for k, v in metadata.items() if v is not None}
    
    with open(filepath, 'w') as f:
        yaml.dump(metadata, f, default_flow_style=False, sort_keys=False, allow_unicode=True)
    
    return filepath


def infer_check_conditions(rule):
    """
    Infer check conditions based on rule metadata
    Returns list of condition dictionaries
    """
    conditions = []
    requirement = rule.get('requirement', '').lower()
    title = rule.get('title', '').lower()
    description = rule.get('description', '').lower()
    scope = rule.get('scope', '').lower()
    
    combined_text = f"{requirement} {title} {description} {scope}"
    
    # Encryption patterns
    if any(word in combined_text for word in ['encrypt', 'encryption', 'cmek', 'kms']):
        conditions.append({
            'var': 'item.encrypted',
            'op': 'equals',
            'value': True
        })
        if 'cmek' in combined_text or 'customer' in combined_text:
            conditions.append({
                'var': 'item.kms_key_id',
                'op': 'exists'
            })
    
    # Public access patterns
    if any(word in combined_text for word in ['public', 'internet', 'external access']):
        if 'no public' in combined_text or 'not public' in combined_text or 'blocked' in combined_text:
            conditions.extend([
                {
                    'var': 'item.public_ip_address',
                    'op': 'not_exists'
                },
                {
                    'var': 'item.internet_facing',
                    'op': 'not_equals',
                    'value': True
                }
            ])
        elif 'public' in combined_text and 'detected' in combined_text:
            conditions.append({
                'var': 'item.public_ip_address',
                'op': 'exists'
            })
    
    # Logging/monitoring patterns
    if any(word in combined_text for word in ['logging', 'logs', 'audit', 'monitor']):
        if 'enabled' in combined_text:
            conditions.append({
                'var': 'item.logging_enabled',
                'op': 'equals',
                'value': True
            })
    
    # VPC/Network patterns
    if 'vpc' in combined_text:
        if 'in vpc' in combined_text or 'vpc configured' in combined_text:
            conditions.append({
                'var': 'item.vpc_id',
                'op': 'exists'
            })
    
    # MFA patterns
    if 'mfa' in combined_text:
        conditions.append({
            'var': 'item.mfa_enabled',
            'op': 'equals',
            'value': True
        })
    
    # SSL/TLS patterns
    if any(word in combined_text for word in ['ssl', 'tls', 'https']):
        if 'enforce' in combined_text or 'required' in combined_text:
            conditions.append({
                'var': 'item.ssl_enabled',
                'op': 'equals',
                'value': True
            })
        if 'tls 1.2' in combined_text or 'minimum' in combined_text:
            conditions.append({
                'var': 'item.min_tls_version',
                'op': 'gte',
                'value': '1.2'
            })
    
    # Backup patterns
    if 'backup' in combined_text:
        if 'enabled' in combined_text or 'configured' in combined_text:
            conditions.append({
                'var': 'item.backup_enabled',
                'op': 'equals',
                'value': True
            })
    
    # Versioning patterns
    if 'version' in combined_text:
        if 'enabled' in combined_text:
            conditions.append({
                'var': 'item.versioning_enabled',
                'op': 'equals',
                'value': True
            })
    
    # Access control patterns
    if any(word in combined_text for word in ['least privilege', 'restricted', 'limited access']):
        conditions.append({
            'var': 'item.permissions',
            'op': 'not_contains',
            'value': '*'
        })
    
    # Port blocking patterns
    port_patterns = {
        'ssh': 22,
        'rdp': 3389,
        'ftp': 21,
        'telnet': 23,
        'mysql': 3306,
        'postgresql': 5432,
        'mongodb': 27017,
        'redis': 6379
    }
    
    for port_name, port_num in port_patterns.items():
        if port_name in combined_text and ('blocked' in combined_text or 'restricted' in combined_text):
            conditions.append({
                'var': f'item.security_group_rules',
                'op': 'not_contains',
                'value': f'0.0.0.0/0:{port_num}'
            })
    
    # Default condition if nothing else matched
    if not conditions:
        conditions.append({
            'var': 'item.id',
            'op': 'exists'
        })
    
    return conditions


def build_discovery_for_resource(service_name, resource_name, service_config):
    """Build discovery configuration for a resource type"""
    
    # Get SDK config
    sdk_config = SERVICE_SDK_CONFIG.get(service_name, DEFAULT_SDK_CONFIG)
    resource_config = sdk_config.get('resources', {}).get(resource_name, {})
    
    if not resource_config:
        # Generate default config
        resource_title = resource_name.replace('_', ' ').title().replace(' ', '')
        resource_config = {
            'list_action': f'Describe{resource_title}s',
            'list_response_key': f'{resource_title}s.{resource_title}',
            'id_field': f'{resource_title}Id'
        }
    
    product = sdk_config.get('product', service_name.upper())
    version = sdk_config.get('version', '2014-05-26')
    
    discovery = {
        'discovery_id': f"alicloud.{service_name}.{resource_name}",
        'calls': [{
            'product': product,
            'version': version,
            'action': resource_config['list_action'],
            'params': {},
            'save_as': f'{resource_name}_response'
        }],
        'emit': {
            'items_for': f'{{ {resource_name}_response.{resource_config["list_response_key"]} }}',
            'as': 'r',
            'item': {
                'id': f'{{{{ r.{resource_config["id_field"]} }}}}',
                'name': '{{ r.Name }}' if 'name' in resource_name else f'{{{{ r.{resource_config["id_field"]} }}}}',
                'resource_type': resource_name,
                'region': '{{ region }}',
                # Add common fields
                'encrypted': '{{ r.Encrypted }}',
                'kms_key_id': '{{ r.KMSKeyId }}',
                'public_ip_address': '{{ r.PublicIpAddress }}',
                'vpc_id': '{{ r.VpcId }}',
                'status': '{{ r.Status }}',
                'tags': '{{ r.Tags }}'
            }
        }
    }
    
    return discovery


def create_service_rules_file(service_dir, service_name, rules):
    """Create service rules YAML file with intelligent SDK-based checks"""
    rules_dir = service_dir / "rules"
    rules_dir.mkdir(parents=True, exist_ok=True)
    
    filepath = rules_dir / f"{service_name}.yaml"
    
    # Group rules by resource type
    resources = defaultdict(list)
    for rule in rules:
        resource = rule.get('resource', 'unknown')
        resources[resource].append(rule)
    
    # Get service SDK config
    service_config = SERVICE_SDK_CONFIG.get(service_name, DEFAULT_SDK_CONFIG)
    
    # Build discovery section with SDK calls
    discovery = []
    for resource in sorted(resources.keys()):
        disc = build_discovery_for_resource(service_name, resource, service_config)
        discovery.append(disc)
    
    # Build checks section with intelligent conditions
    checks = []
    for rule in rules:
        rule_id = rule.get('rule_id')
        resource = rule.get('resource', 'unknown')
        
        # Infer conditions from rule metadata
        inferred_conditions = infer_check_conditions(rule)
        
        check = {
            'rule_id': rule_id,
            'title': rule.get('title', ''),
            'severity': rule.get('severity', 'medium'),
            'assertion_id': rule.get('compliance', [''])[0] if rule.get('compliance') else '',
            'for_each': f"alicloud.{service_name}.{resource}",
            'params': {},
            'conditions': {
                'all': inferred_conditions
            } if len(inferred_conditions) > 1 else inferred_conditions[0] if inferred_conditions else {
                'var': 'item.id',
                'op': 'exists'
            }
        }
        
        checks.append(check)
    
    # Create the YAML structure
    service_yaml = {
        'version': '1.0',
        'provider': 'alicloud',
        'service': service_name,
        'discovery': discovery,
        'checks': checks
    }
    
    with open(filepath, 'w') as f:
        yaml.dump(service_yaml, f, default_flow_style=False, sort_keys=False, allow_unicode=True, width=120)
    
    return filepath


def regenerate_services():
    """Main function to regenerate services folder with enhanced checks"""
    print("="*80)
    print("ALICLOUD SERVICES REGENERATION - ENHANCED WITH SDK CHECKS")
    print("="*80)
    
    # Load rules
    rules = load_rules()
    
    # Group by service
    services = group_by_service(rules)
    
    # Create backup
    if SERVICES_DIR.exists():
        backup_dir = BASE_DIR / "services_backup_old"
        if backup_dir.exists():
            import shutil
            shutil.rmtree(backup_dir)
        print(f"\nBacking up existing services to {backup_dir}...")
        import shutil
        shutil.copytree(SERVICES_DIR, backup_dir)
    
    # Recreate services directory
    print(f"\nRecreating {SERVICES_DIR}...")
    if SERVICES_DIR.exists():
        import shutil
        shutil.rmtree(SERVICES_DIR)
    SERVICES_DIR.mkdir(parents=True, exist_ok=True)
    
    # Process each service
    print("\nGenerating service files with intelligent checks...")
    total_metadata = 0
    total_services = 0
    
    for service_name, service_rules in sorted(services.items()):
        print(f"\n  Processing {service_name}...")
        service_dir = SERVICES_DIR / service_name
        service_dir.mkdir(parents=True, exist_ok=True)
        
        # Create metadata files
        print(f"    Creating {len(service_rules)} metadata files...")
        for rule in service_rules:
            create_metadata_file(service_dir, rule)
            total_metadata += 1
        
        # Create service rules file with SDK checks
        print(f"    Creating rules file with SDK-based checks...")
        create_service_rules_file(service_dir, service_name, service_rules)
        total_services += 1
    
    print("\n" + "="*80)
    print("REGENERATION COMPLETE - ENHANCED")
    print("="*80)
    print(f"  Services created: {total_services}")
    print(f"  Metadata files created: {total_metadata}")
    print(f"  Rules with SDK checks: {total_metadata}")
    print(f"  Location: {SERVICES_DIR}")
    print("="*80)
    print("\nâœ… All services now include:")
    print("  - SDK-based discovery calls")
    print("  - Intelligent check conditions")
    print("  - Field mappings from AliCloud APIs")
    print("="*80)


if __name__ == "__main__":
    regenerate_services()











