rule_id: ibm.watson_ml.deployment.ai_services_inference_endpoint_private_networking_enforced
title: Enforce Private Networking for AI Services Inference Endpoints
severity: medium
domain: network_security_and_connectivity
subcategory: network_access_control
rationale: Enforcing private networking for AI services inference endpoints is crucial
  to safeguard sensitive data and maintain the integrity of AI models. By restricting
  endpoint access to private networks, organizations minimize the risk of unauthorized
  access and data breaches, ensuring compliance with industry regulations and protecting
  intellectual property.
description: This rule verifies that AI services inference endpoints within Watson
  Machine Learning deployments are configured to enforce private networking. It ensures
  that these endpoints are accessible only through IBM Cloud's private network infrastructure,
  reducing exposure to public internet threats. By implementing private networking,
  organizations enhance their security posture, mitigate potential attack vectors,
  and align with compliance requirements such as GDPR and HIPAA. This practice not
  only fortifies network access control but also fosters a secure environment for
  deploying and managing AI models.
references:
- https://cloud.ibm.com/docs/watson-machine-learning?topic=watson-machine-learning-deploy-private-endpoints
- https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-overview
- https://cloud.ibm.com/docs/vpc?topic=vpc-networking-overview
- https://cloud.ibm.com/docs/watson?topic=watson-security
- https://cloud.ibm.com/docs/overview?topic=overview-security
