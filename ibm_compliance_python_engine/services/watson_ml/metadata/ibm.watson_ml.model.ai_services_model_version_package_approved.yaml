rule_id: ibm.watson_ml.model.ai_services_model_version_package_approved
title: Ensure AI Model Version Packages are Approved in Watson ML
severity: low
domain: compliance_and_governance
subcategory: security_monitoring
rationale: Ensuring that AI model version packages are approved before deployment
  is crucial for maintaining a secure and reliable machine learning environment. Unapproved
  models may contain vulnerabilities or unauthorized modifications that can lead to
  data breaches, compromise model integrity, or introduce biases. By enforcing this
  rule, organizations can safeguard their AI assets, uphold data privacy standards,
  and ensure compliance with industry regulations.
description: This rule checks that all AI model version packages within IBM Watson
  Machine Learning are approved before they are deployed or used in production environments.
  The verification process involves confirming that the model packages meet organizational
  standards and have passed all necessary security and compliance assessments. Implementing
  this rule helps improve security by preventing the deployment of potentially harmful
  or non-compliant model versions. It also aids in maintaining an auditable trail
  of model approval processes, which is beneficial for compliance with regulatory
  requirements such as GDPR and industry-specific standards.
references:
- https://cloud.ibm.com/docs/watson-machine-learning?topic=watson-machine-learning-ml-overview
- https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-get-started
- https://cloud.ibm.com/docs/watson?topic=watson-ml-security
